{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        " !pip install polars efficient-apriori great-tables"
      ],
      "metadata": {
        "id": "WjKGzqDmkADK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S77QjuIdjrm6"
      },
      "outputs": [],
      "source": [
        "   # Importar las librerías necesarias\n",
        "import polars as pl\n",
        "from efficient_apriori import apriori\n",
        "from great_tables import GT, loc, style\n",
        "\n",
        "def main():\n",
        "    # Datos de las transacciones (mejor estructuración)\n",
        "    transacciones = [\n",
        "        [\"Milk\", \"Bread\", \"Butter\"],\n",
        "        [\"Milk\", \"Bread\"],\n",
        "        [\"Bread\", \"Butter\"],\n",
        "        [\"Milk\", \"Butter\"],\n",
        "        [\"Milk\", \"Bread\", \"Butter\"]\n",
        "    ]\n",
        "\n",
        "    # Aplicar el algoritmo Apriori con parámetros ajustados\n",
        "    itemsets, rules = apriori(\n",
        "        transacciones,\n",
        "        min_support=0.3,  # Aumentado para este dataset pequeño\n",
        "        min_confidence=0.6  # Aumentado para reglas más significativas\n",
        "    )\n",
        "\n",
        "    # Procesamiento más eficiente de las reglas\n",
        "    if not rules:\n",
        "        print(\"No se encontraron reglas significativas con los parámetros actuales.\")\n",
        "        return\n",
        "\n",
        "    # Extracción de métricas en una sola iteración\n",
        "    rule_data = {\n",
        "        \"Antecedente\": [list(rule.lhs) for rule in rules],\n",
        "        \"Consecuente\": [list(rule.rhs) for rule in rules],\n",
        "        \"Confianza\": [round(rule.confidence, 3) for rule in rules],\n",
        "        \"Soporte\": [round(rule.support, 3) for rule in rules],\n",
        "        \"Lift\": [round(rule.lift, 3) for rule in rules]\n",
        "    }\n",
        "\n",
        "    # Creación del DataFrame con Polars\n",
        "    df_rules = pl.DataFrame(rule_data).sort(\"Lift\", descending=True)\n",
        "\n",
        "    # Visualización mejorada\n",
        "    print(\"\\n=== REGLAS DE ASOCIACIÓN ENCONTRADAS ===\")\n",
        "    print(df_rules)\n",
        "\n",
        "    # Creación de tabla visual con Great Tables\n",
        "    if len(df_rules) > 0:\n",
        "        gt_table = (\n",
        "            GT(df_rules.to_pandas())\n",
        "            .tab_header(title=\"Análisis de Reglas de Asociación\")\n",
        "            .fmt_number(columns=[\"Confianza\", \"Soporte\", \"Lift\"], decimals=3)\n",
        "            .data_color(\n",
        "                columns=[\"Lift\"],\n",
        "                palette=[\"red\", \"green\"],\n",
        "                domain=[min(rule_data[\"Lift\"]), max(rule_data[\"Lift\"])]\n",
        "            )\n",
        "        )\n",
        "        print(\"\\nVisualización tabular:\")\n",
        "        display(gt_table)  # Para entornos como Jupyter/Colab\n",
        "\n",
        "    print(\"\\nJannet Ortiz Aguilar\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Datos de las transacciones\n",
        "transacciones = [\n",
        "    [\"Milk\", \"Bread\", \"Butter\"],\n",
        "    [\"Milk\", \"Bread\"],\n",
        "    [\"Bread\", \"Butter\"],\n",
        "    [\"Milk\", \"Butter\"],\n",
        "    [\"Milk\", \"Bread\", \"Butter\"]\n",
        "]\n",
        "\n",
        "# Se aplica el algoritmo TransactionEncoder para transformar las transacciones\n",
        "encoder = TransactionEncoder()\n",
        "encoded_array = encoder.fit(transacciones).transform(transacciones)\n",
        "\n",
        "# Se converte los datos transformados en un DataFrame\n",
        "df = pd.DataFrame(encoded_array, columns=encoder.columns_)\n",
        "\n",
        "# Se calculan los patrones frecuentes (soporte mínimo de 0.1) y reglas de asociación (soporte mínimo de 0.6 para el lift)\n",
        "frequent_itemsets = fpgrowth(df, min_support=0.1, use_colnames=True)\n",
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.6)\n",
        "\n",
        "# Se Convierte los conjuntos de antecedente y consecuente en listas para que sean más legibles\n",
        "rules['antecedents'] = rules['antecedents'].apply(lambda x: list(x))\n",
        "rules['consequents'] = rules['consequents'].apply(lambda x: list(x))\n",
        "print(rules)\n",
        "\n",
        "# Se Seleccionan las columnas relevantes: antecedentes, consecuentes, confianza, soporte y lift\n",
        "result = rules[['antecedents', 'consequents', 'confidence', 'support', 'lift']]\n",
        "\n",
        "# Se da formato a la tabla utilizando tabulate para hacerla más legible\n",
        "formatted_result = tabulate(result, headers='keys', tablefmt='fancy_grid', showindex=False)\n",
        "\n",
        "# Imprimir la tabla formateada\n",
        "print(formatted_result)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Jannet Ortiz Aguilar\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "tLOB4Gxwmqu0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}