""" Introducci√≥n: para determinar el valor √≥ptimo de k en el modelo KNN, el c√≥digo implementado es un flujo estructurado que incluye:
1) Divisi√≥n de datos (train_test_split) para entrenamiento y prueba.
2) Normalizaci√≥n (StandardScaler) para estandarizar las variables.
3) Evaluaci√≥n iterativa de m√∫ltiples valores de *k* (1 a 20).
4) C√°lculo del RMSE para medir el error en cada iteraci√≥n.
5) Selecci√≥n autom√°tica del *k* con menor error (np.argmin).
Estos componentes, respaldados por visualizaciones claras, aseguran un equilibrio entre precisi√≥n y generalizaci√≥n, evitando sobreajuste (*k* bajo) o subajuste (*k* alto). El proceso es reproducible y sistem√°tico."""

# -*- c√≥digo-*-
"""KNN_Regresion_Analisis_Estadistico_Completo_Corregido.ipynb

C√≥digo completo con:
- Regresi√≥n KNN funcional
- An√°lisis estad√≠stico completo
"""

# 1. Instalaci√≥n de dependencias
!pip install polars scikit-learn matplotlib seaborn imbalanced-learn --quiet
import os

# 2. Importaci√≥n de librer√≠as
import polars as pl
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from google.colab import files
from sklearn.utils import resample
import pandas as pd

# 3. Configuraci√≥n de estilos
plt.style.use('seaborn-v0_8')
sns.set_theme(style="whitegrid", palette="husl")
%matplotlib inline

# 4. Funci√≥n para cargar datos
def load_data():
    """Carga datos con m√∫ltiples opciones."""
    print("\n" + "="*50)
    print(" OPCIONES DE CARGA DE DATOS ".center(50, "="))
    print("="*50)
    print("1. Usar ruta por defecto (/content/Students_Grading_Dataset.csv)")
    print("2. Ingresar ruta manualmente")
    print("3. Subir archivo manualmente")
    
    choice = input("\nSeleccione opci√≥n (1-3): ")
    
    try:
        if choice == "1":
            path = "/content/Students_Grading_Dataset.csv"
        elif choice == "2":
            path = input("Ingrese la ruta completa al archivo CSV: ").strip()
        elif choice == "3":
            print("\nPor favor, suba su archivo CSV:")
            uploaded = files.upload()
            path = list(uploaded.keys())[0]
        else:
            raise ValueError("Opci√≥n no v√°lida")
        
        df = pl.read_csv(path)
        print(f"\n‚úÖ Datos cargados exitosamente desde: {path}")
        print(f"üìä Dimensiones: {df.shape[0]} filas x {df.shape[1]} columnas")
        return df
        
    except Exception as e:
        print(f"\n‚ùå Error al cargar datos: {str(e)}")
        raise

# 5. Carga de datos
try:
    df = load_data()
    print("\nüîç Muestra de datos (5 primeras filas):")
    print(df.head())
except Exception as e:
    print(f"\n‚ö†Ô∏è No se pudo cargar el archivo. Error: {e}")
    raise

# 6. An√°lisis Exploratorio Inicial
print("\n" + "="*50)
print(" AN√ÅLISIS EXPLORATORIO ".center(50, "="))
print("="*50)

# 6.1 Tipos de datos
plt.figure(figsize=(12, 4))
dtypes = [str(dt) for dt in df.schema.values()]
sns.barplot(x=list(df.columns), y=dtypes, palette="Blues_d")
plt.title('Tipos de Datos por Columna', pad=15)
plt.xticks(rotation=45)
plt.ylabel('Tipo de Dato')
plt.tight_layout()
plt.show()

# 6.2 Selecci√≥n de variable objetivo
def select_target(df):
    """Selecci√≥n interactiva de variable objetivo."""
    numeric_cols = [col for col in df.columns 
                   if df[col].dtype in (pl.Float64, pl.Float32, pl.Int64, pl.Int32)]
    
    if not numeric_cols:
        raise ValueError("No se encontraron columnas num√©ricas")
    
    # Visualizaci√≥n de distribuciones
    print("\nüìä Distribuciones de variables num√©ricas:")
    plt.figure(figsize=(15, 10))
    for i, col in enumerate(numeric_cols, 1):
        plt.subplot((len(numeric_cols)//3)+1, 3, i)
        sns.histplot(df[col].to_numpy(), kde=True, color='skyblue')
        plt.title(f'Distribuci√≥n de {col}', fontsize=10)
    plt.tight_layout()
    plt.show()
    
    # Selecci√≥n interactiva
    print("\nüî¢ Seleccione la columna objetivo:")
    for i, col in enumerate(numeric_cols, 1):
        print(f"{i}. {col}")
    
    while True:
        try:
            choice = int(input("\nIngrese el n√∫mero de la columna objetivo: "))
            if 1 <= choice <= len(numeric_cols):
                selected_col = numeric_cols[choice-1]
                
                if df[selected_col].dtype in (pl.Int32, pl.Int64):
                    print(f"‚ö†Ô∏è Convirtiendo '{selected_col}' a float...")
                    df = df.with_columns(pl.col(selected_col).cast(pl.Float64))
                
                return df, selected_col
            print("‚ùå N√∫mero fuera de rango. Intente nuevamente.")
        except ValueError:
            print("‚ùå Ingrese un n√∫mero v√°lido.")

try:
    df, TARGET_COL = select_target(df)
    print(f"\nüéØ Columna objetivo seleccionada: '{TARGET_COL}'")
    
    # Visualizaci√≥n de la variable objetivo
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    sns.boxplot(y=df[TARGET_COL].to_numpy(), color='lightblue')
    plt.title('Diagrama de Caja')
    
    plt.subplot(1, 2, 2)
    sns.histplot(df[TARGET_COL].to_numpy(), kde=True, color='lightgreen')
    plt.title('Distribuci√≥n')
    plt.tight_layout()
    plt.show()
    
except Exception as e:
    print(f"\n‚ùå Error en selecci√≥n de variable objetivo: {e}")
    raise

# 7. Ingenier√≠a de Caracter√≠sticas
print("\n" + "="*50)
print(" INGENIER√çA DE CARACTER√çSTICAS ".center(50, "="))
print("="*50)

# 7.1 Eliminar columnas irrelevantes
irrelevant_cols = ['Student_ID', 'First_Name', 'Last_Name', 'Email']
df = df.drop([col for col in irrelevant_cols if col in df.columns])

# 7.2 Procesamiento de variables categ√≥ricas
categorical_cols = [col for col in df.columns if df[col].dtype == pl.Utf8 and col != TARGET_COL]
print(f"üß† Variables categ√≥ricas a transformar: {categorical_cols}")

if categorical_cols:
    # Guardar nombres originales para referencia
    original_categorical_cols = categorical_cols.copy()
    
    # Aplicar one-hot encoding
    df = df.to_dummies(columns=categorical_cols)
    
    # Obtener nuevas columnas dummy creadas
    dummy_cols = [col for col in df.columns 
                 if any(col.startswith(cat_col) for cat_col in original_categorical_cols)]
    
    print(f"\nüìê Nuevas columnas tras one-hot encoding: {df.shape[1]}")
    print("\nüîç Muestra de columnas transformadas:")
    
    # Mostrar solo algunas columnas dummy como ejemplo (m√°ximo 5)
    sample_dummy_cols = dummy_cols[:min(5, len(dummy_cols))]
    print(df.select(sample_dummy_cols).head())

# 8. An√°lisis Estad√≠stico Completo
print("\n" + "="*50)
print(" AN√ÅLISIS ESTAD√çSTICO ".center(50, "="))
print("="*50)

# 8.1 Funci√≥n para identificar columnas num√©ricas
def get_numeric_cols(df):
    """Identifica columnas num√©ricas excluyendo la objetivo."""
    numeric_types = (pl.Int8, pl.Int16, pl.Int32, pl.Int64, 
                    pl.UInt8, pl.UInt16, pl.UInt32, pl.UInt64,
                    pl.Float32, pl.Float64)
    return [col for col in df.columns 
            if df[col].dtype in numeric_types and col != TARGET_COL]

numeric_cols = get_numeric_cols(df)
if not numeric_cols:
    raise ValueError("No se encontraron columnas num√©ricas para an√°lisis")

print(f"üî¢ Columnas num√©ricas para an√°lisis: {numeric_cols}")

# 8.2 Matriz de Correlaci√≥n (con tama√±o de letra ajustado)
print("\nüìä Matriz de Correlaci√≥n:")
corr_matrix = df.select(numeric_cols + [TARGET_COL]).to_pandas().corr()

plt.figure(figsize=(12, 10))
heatmap = sns.heatmap(
    corr_matrix,
    annot=True,
    annot_kws={'size': 8},  # Tama√±o de fuente reducido
    fmt=".2f",
    cmap='coolwarm',
    center=0,
    vmin=-1,
    vmax=1,
    linewidths=0.5,
    cbar_kws={"label": "Coeficiente de Correlaci√≥n", "shrink": 0.75}
)

# Ajustar tama√±o de letra de los ejes
heatmap.set_xticklabels(heatmap.get_xticklabels(), 
                       rotation=45, 
                       ha='right',
                       fontsize=9)

heatmap.set_yticklabels(heatmap.get_yticklabels(), 
                       rotation=0,
                       fontsize=9)

plt.title('Matriz de Correlaci√≥n', pad=20, fontsize=12)
plt.tight_layout()
plt.show()

# 8.3 An√°lisis de Varianza
print("\nüìà An√°lisis de Varianza:")
variance_df = df.select([pl.col(col).var().alias(col) for col in numeric_cols])

plt.figure(figsize=(12, 6))
ax = sns.barplot(data=variance_df.transpose().to_pandas(), palette='viridis')
plt.title('Varianza por Variable', pad=20, fontsize=14)
plt.xlabel('Variables')
plt.ylabel('Varianza')
plt.xticks(rotation=45)

# A√±adir etiquetas de valor
for p in ax.patches:
    ax.annotate(f"{p.get_height():.2f}", 
                (p.get_x() + p.get_width()/2., p.get_height()), 
                ha='center', va='center', 
                xytext=(0, 10), 
                textcoords='offset points',
                fontsize=9)
plt.tight_layout()
plt.show()

# 9. Modelado KNN (Versi√≥n Corregida con manejo de desbalance)
print("\n" + "="*50)
print(" MODELADO KNN ".center(50, "="))
print("="*50)

# 9.1 Preparaci√≥n de datos
X = df.select(numeric_cols).to_numpy()
y = df[TARGET_COL].to_numpy()

# Discretizaci√≥n de la variable objetivo para an√°lisis de balance
# Convertir a Pandas para usar pd.cut
y_pd = pd.Series(y)
y_binned = pd.cut(y_pd, bins=3, labels=['Low', 'Medium', 'High'])
class_distribution = y_binned.value_counts(normalize=True)

print("\nüìä Distribuci√≥n de clases (discretizadas):")
print(class_distribution)

# 9.1.1 Verificar desbalance significativo
if class_distribution.max() > 0.7:  # Si una clase tiene m√°s del 70%
    print("\n‚ö†Ô∏è Advertencia: Distribuci√≥n desbalanceada detectada")
    print("üîß Aplicando t√©cnicas de balanceo...")
    
    # Convertir a DataFrame para balanceo
    df_pd = df.select(numeric_cols + [TARGET_COL]).to_pandas()
    df_pd['target_binned'] = pd.cut(df_pd[TARGET_COL], bins=3, labels=['Low', 'Medium', 'High'])
    
    # Separar por clases
    majority_class = class_distribution.idxmax()
    minority_classes = [c for c in class_distribution.index if c != majority_class]
    
    df_majority = df_pd[df_pd.target_binned == majority_class]
    df_minorities = [df_pd[df_pd.target_binned == c] for c in minority_classes]
    
    # Balancear todas las clases
    n_samples = min(len(df_majority), *[len(df) for df in df_minorities])
    
    # Downsample majority class
    df_majority_downsampled = df_majority.sample(n=n_samples, random_state=42)
    
    # Upsample minority classes
    df_minorities_upsampled = [df.sample(n=n_samples, replace=True, random_state=42) 
                              for df in df_minorities]
    
    # Combinar
    df_balanced = pd.concat([df_majority_downsampled] + df_minorities_upsampled)
    
    # Ver nueva distribuci√≥n
    print("\nüìä Nueva distribuci√≥n despu√©s del balanceo:")
    print(df_balanced.target_binned.value_counts(normalize=True))
    
    # Preparar datos balanceados
    X = df_balanced[numeric_cols].values
    y = df_balanced[TARGET_COL].values
else:
    print("\n‚úÖ Los datos est√°n balanceados, procediendo sin ajustes")

# Escalado
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Divisi√≥n train-test
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42)

# 9.2 B√∫squeda del mejor k
print("\nüîç Buscando el mejor valor de k...")
k_range = range(1, 21)
rmse_scores = []

for k in k_range:
    knn = KNeighborsRegressor(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # Correcci√≥n aplicada aqu√≠
    rmse_scores.append(rmse)
    print(f"k={k:2d}: RMSE = {rmse:.4f}")

# Visualizaci√≥n del RMSE
plt.figure(figsize=(10, 6))
plt.plot(k_range, rmse_scores, marker='o', linestyle='--', color='royalblue')
plt.title('RMSE para diferentes valores de k', pad=15)
plt.xlabel('N√∫mero de vecinos (k)')
plt.ylabel('RMSE')
plt.xticks(k_range)
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()

best_k = k_range[np.argmin(rmse_scores)]
print(f"\n‚úÖ Mejor valor de k: {best_k} con RMSE = {min(rmse_scores):.4f}")

# 9.3 Modelo final (Versi√≥n Corregida)
print("\nüèÜ Entrenando modelo final con el mejor k...")
final_knn = KNeighborsRegressor(n_neighbors=best_k)
final_knn.fit(X_train, y_train)
final_preds = final_knn.predict(X_test)

# M√©tricas finales (Correcci√≥n aplicada aqu√≠)
final_r2 = r2_score(y_test, final_preds)
final_rmse = np.sqrt(mean_squared_error(y_test, final_preds))  # Calculamos RMSE manualmente

print("\nüìä Resultados del modelo final:")
print(f"- R¬≤: {final_r2:.4f}")
print(f"- RMSE: {final_rmse:.4f}")

# Visualizaci√≥n de predicciones vs reales
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test, y=final_preds, alpha=0.6, color='royalblue')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 
         linestyle='--', color='red', linewidth=1)
plt.title('Predicciones vs Valores Reales', pad=15)
plt.xlabel('Valores Reales')
plt.ylabel('Predicciones')
plt.grid(True, linestyle='--', alpha=0.3)
plt.show()

print("\n" + "="*50)
print(" AN√ÅLISIS COMPLETADO ".center(50, "="))
print("="*50)


# 9.4 Visualizaci√≥n de Errores (Alternativa a Matriz de Confusi√≥n para Regresi√≥n)
print("\nüìà Visualizaci√≥n de Errores de Predicci√≥n")

# Crear bins para discretizar las predicciones y valores reales
bins = np.linspace(min(y_test.min(), final_preds.min()), 
                   max(y_test.max(), final_preds.max()), 10)

y_test_binned = np.digitize(y_test, bins)
preds_binned = np.digitize(final_preds, bins)

# Crear matriz de conteo
confusion_matrix = np.zeros((len(bins)+1, len(bins)+1))
for true, pred in zip(y_test_binned, preds_binned):
    confusion_matrix[true-1, pred-1] += 1

# Visualizaci√≥n
plt.figure(figsize=(10, 8))
sns.heatmap(confusion_matrix, annot=True, fmt='.0f', cmap='Blues',
            xticklabels=[f"{bins[i-1]:.1f}-{bins[i]:.1f}" for i in range(len(bins))],
            yticklabels=[f"{bins[i-1]:.1f}-{bins[i]:.1f}" for i in range(len(bins))])
plt.title('Distribuci√≥n de Predicciones vs Valores Reales', pad=20)
plt.xlabel('Predicciones (binned)')
plt.ylabel('Valores Reales (binned)')
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

# Alternativa: Gr√°fico de dispersi√≥n con residuos
plt.figure(figsize=(12, 6))
residuals = y_test - final_preds
sns.scatterplot(x=final_preds, y=residuals, alpha=0.6, color='royalblue')
plt.axhline(y=0, color='r', linestyle='--')
plt.title('An√°lisis de Residuos', pad=15)
plt.xlabel('Predicciones')
plt.ylabel('Residuos (Real - Predicci√≥n)')
plt.grid(True, linestyle='--', alpha=0.3)
plt.show()

print("\n" + "="*50)
print(" AN√ÅLISIS COMPLETADO ".center(50, "="))
print(" Hecho por: Jannet Ortiz Aguilar".center(50, "="))
print("="*50)

![image](https://github.com/user-attachments/assets/264fba30-f5d0-4a04-bd8d-e9980d159ecd)

![image](https://github.com/user-attachments/assets/27c41925-6dc1-498d-9a8d-2759699eddfc)

![image](https://github.com/user-attachments/assets/fe91c3ae-4f9e-4476-bd11-fb58ee36a26c)

![image](https://github.com/user-attachments/assets/d1e1e3e4-0f79-4fef-bc2d-0e86b65000d2)

![image](https://github.com/user-attachments/assets/c7359dac-6415-41d5-9eeb-c806fb6e883d)

üî¢ Columnas num√©ricas para an√°lisis: ['Gender_Female', 'Gender_Male', 'Age', 'Department_Business', 'Department_CS', 'Department_Engineering', 'Department_Mathematics', 'Attendance (%)', 'Midterm_Score', 'Final_Score', 'Assignments_Avg', 'Quizzes_Avg', 'Participation_Score', 'Projects_Score', 'Total_Score', 'Grade_A', 'Grade_B', 'Grade_C', 'Grade_D', 'Grade_F', 'Extracurricular_Activities_No', 'Extracurricular_Activities_Yes', 'Internet_Access_at_Home_No', 'Internet_Access_at_Home_Yes', "Parent_Education_Level_Bachelor's", 'Parent_Education_Level_High School', "Parent_Education_Level_Master's", 'Parent_Education_Level_None', 'Parent_Education_Level_PhD', 'Family_Income_Level_High', 'Family_Income_Level_Low', 'Family_Income_Level_Medium', 'Stress_Level (1-10)', 'Sleep_Hours_per_Night']

![image](https://github.com/user-attachments/assets/553f383f-7cad-416a-ad04-a4f8cae867d2)

![image](https://github.com/user-attachments/assets/ef1c1b1c-3c90-41f5-8286-232559ad44b3)

![image](https://github.com/user-attachments/assets/04a02d7f-990e-4051-8c8f-847f3f56d72f)

![image](https://github.com/user-attachments/assets/ad8a3c34-f61c-4e0b-b7dd-5ffe98137ffe)

![image](https://github.com/user-attachments/assets/ea317878-04b0-4011-a3ce-bf8c5628aa88)

![image](https://github.com/user-attachments/assets/b90c3f35-21e4-4d92-8fdb-a931493ce455)

![image](https://github.com/user-attachments/assets/bab089a4-7e3d-4353-8dc0-75f7416cbfe5)


Nota: en el siguiente link: https://colab.research.google.com/?hl=es&authuser=1#scrollTo=oQqvzcF15Wpo&uniqifier=3, se encuentran una revisi√≥n del c√≥digo para las variables objetivas: 

![image](https://github.com/user-attachments/assets/5a3ea010-ccb9-48d7-937c-74588334e511)


"""Conclusi√≥n: es posible que los resultados finales analizados del modelo KNN revelen un claro fracaso predictivo, evidenciado por el coeficientes R¬≤ negativos (entre -0.08 y -0.03) en todas las variables analizadas, lo que indica que el modelo es menos √∫til que predecir el valor medio. Adicionalmente, aunque algunas variables como Age mostraron un RMSE relativamente bajo (2.02), esto no compensa la incapacidad del modelo para explicar patrones en los datos. Por otro lado, el balanceo evit√≥ sesgos hacia categor√≠as espec√≠ficas (como Medium), pero no resolvi√≥ el problema central: el KNN no captura relaciones significativas en este conjunto de datos"""

Por lo que ahora vamos a entrenar el modelo

# =============================================
# IMPORTACI√ìN DE LIBRER√çAS
# =============================================
import polars as pl
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from imblearn.over_sampling import SMOTE
from tqdm import tqdm

# =============================================
# CARGA Y PREPROCESAMIENTO DE DATOS
# =============================================
print("üîπ Cargando y preprocesando datos...")
df = pl.read_csv("Students_Grading_Dataset.csv")

# Eliminar columnas irrelevantes
df = df.drop(["Student_ID", "First_Name", "Last_Name", "Email"])

# Codificaci√≥n de variables categ√≥ricas
categorical_cols = [
    "Gender", "Department", "Grade", "Extracurricular_Activities",
    "Internet_Access_at_Home", "Parent_Education_Level", "Family_Income_Level"
]

label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    df = df.with_columns(pl.Series(name=col, values=le.fit_transform(df[col].to_list())))
    label_encoders[col] = le

class_names = label_encoders["Grade"].classes_

# Separar variables predictoras y objetivo
X = df.drop("Grade").to_numpy()
y = df["Grade"].to_numpy()

# Divisi√≥n del conjunto de datos
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# Balanceo con SMOTE
print("üîπ Aplicando SMOTE...")
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

# Normalizaci√≥n
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_balanced)
X_test_scaled = scaler.transform(X_test)

# =============================================
# B√öSQUEDA DE HIPERPAR√ÅMETROS
# =============================================
print("\nüîç Buscando el mejor k y tipo de pesos...")
param_grid = {
    "n_neighbors": range(3, 15),
    "weights": ["uniform", "distance"],
    "metric": ["euclidean", "manhattan"]
}

grid_search = GridSearchCV(
    estimator=KNeighborsClassifier(),
    param_grid=param_grid,
    scoring="accuracy",
    cv=5,
    n_jobs=-1
)
grid_search.fit(X_train_scaled, y_train_balanced)

best_knn = grid_search.best_estimator_
print(f"‚úÖ Mejor modelo: {grid_search.best_params_} con accuracy={grid_search.best_score_:.4f}")

# =============================================
# EVALUACI√ìN DEL MODELO
# =============================================
print("\nüìä Evaluando modelo...")

# Reporte de clasificaci√≥n
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nüìù Reporte de Clasificaci√≥n:\n", classification_report(y_test, y_pred, target_names=class_names))

# Matriz de confusi√≥n
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Greens", xticklabels=class_names, yticklabels=class_names)
plt.title("Matriz de Confusi√≥n")
plt.xlabel("Predicho")
plt.ylabel("Real")
plt.show()

# üîç üî¥ Visualizaci√≥n de errores de predicci√≥n
import pandas as pd

# DataFrame con predicciones y reales
error_df = pd.DataFrame({
    "Real": label_encoders["Grade"].inverse_transform(y_test),
    "Predicho": label_encoders["Grade"].inverse_transform(y_pred)
})
error_df["Correcto"] = error_df["Real"] == error_df["Predicho"]

# Gr√°fico de errores por clase real
error_counts = error_df[~error_df["Correcto"]].groupby("Real").size().sort_values(ascending=False)

plt.figure(figsize=(10, 5))
sns.barplot(x=error_counts.index, y=error_counts.values, palette="Reds_r")
plt.title("Errores de Clasificaci√≥n por Clase Real")
plt.ylabel("Cantidad de Errores")
plt.xlabel("Clase Real")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Heatmap de Real vs Predicho
error_matrix = pd.crosstab(error_df["Real"], error_df["Predicho"])
plt.figure(figsize=(8, 6))
sns.heatmap(error_matrix, annot=True, fmt="d", cmap="YlGnBu")
plt.title("Errores de Clasificaci√≥n (Real vs Predicho)")
plt.xlabel("Predicho")
plt.ylabel("Real")
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

# =============================================
# EVALUACI√ìN ADICIONAL POR M√âTRICA DE DISTANCIA
# =============================================
print("\nüìê Evaluaci√≥n de diferentes m√©tricas y valores de k...")
k_values = range(1, 21, 2)
distance_metrics = ['euclidean', 'manhattan', 'cosine']
cv_scores = {}

for metric in distance_metrics:
    print(f"\nüî∏ M√©trica: {metric}")
    scores_list = []
    for k in tqdm(k_values, desc=f"k={metric}"):
        knn_model = KNeighborsClassifier(n_neighbors=k, metric=metric)
        scores = cross_val_score(knn_model, X_train_scaled, y_train_balanced, cv=5, scoring="accuracy")
        scores_list.append(scores.mean())
    cv_scores[metric] = scores_list
    best_k = k_values[np.argmax(scores_list)]
    print(f"‚úÖ Mejor k: {best_k} con accuracy={max(scores_list):.4f}")

# Visualizaci√≥n comparativa
plt.figure(figsize=(10, 6))
for metric in cv_scores:
    plt.plot(k_values, cv_scores[metric], marker='o', label=f"{metric}")
plt.title("Comparaci√≥n de Accuracy por k y M√©trica de Distancia")
plt.xlabel("Valor de k")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

print("\n‚úÖ An√°lisis completado con √©xito.")

RESULTADO

![image](https://github.com/user-attachments/assets/dd4f561e-e464-4e2b-b23e-25d61e427714)

![image](https://github.com/user-attachments/assets/9123c8c4-3811-4158-9e02-a94f3d6b750b)

![image](https://github.com/user-attachments/assets/7a71c133-6eff-4a87-b9a8-f5f1c08e8487)

![image](https://github.com/user-attachments/assets/c9295128-2a18-41cc-b50a-dbaf0e778f8c)

